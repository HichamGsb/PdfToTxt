<?xml version='1.0' encoding='UTF-8'?>
<article>

<preamble>
marcu_statistics_sentence_pass_one.txt

</preamble>

<titre>
Statistics-Based Summarization — Step One: Sentence Compression 

</titre>

<auteur>
                                           Kevin Knight and Daniel Marcu
                            Information Sciences Institute and Department of Computer Science
                                             University of Southern California
                                             4676 Admiralty Way, Suite 1001
                                                Marina del Rey, CA 90292
                                                  {knight,marcu}@isi.edu


</auteur>

<abstract>
When humans produce summaries of documents, they
do not simply extract sentences and concatenate them.
Rather, they create new sentences that are grammati-
cal, that cohere with one another, and that capture the
most salient pieces of information in the original doc-
ument. Given that large collections of text/abstract
pairs are available online, it is now possible to envision
algorithms that are trained to mimic this process. In
this paper, we focus on sentence compression, a sim-
pler version of this larger challenge. We aim to achieve
two goals simultaneously: our compressions should be
grammatical, and they should retain the most impor-
tant pieces of information. These two goals can con-
ﬂict. We devise both noisy-channel and decision-tree
approaches to the problem, and we evaluate results
against manual compressions and a simple baseline.

</abstract>

<biblio>
References test


</biblio>

</article>